{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33bf3829-103e-45fa-b5f0-eb7f2433c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import time  # For adding delays\n",
    "import random  # For randomizing delay times\n",
    "\n",
    "def scrape_scholar_articles(query, num_pages):\n",
    "    articles = []\n",
    "    page = 0\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    while page < num_pages:\n",
    "        url = f\"https://scholar.google.com/scholar?start={page*10}&q={query}&hl=en&as_sdt=0,5\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        results = soup.find_all(\"div\", class_=\"gs_ri\")\n",
    "        \n",
    "        for result in results:\n",
    "            # Extract title\n",
    "            title = result.find(\"h3\", class_=\"gs_rt\").text\n",
    "            \n",
    "            # Extract snippet containing authors, publisher, and year\n",
    "            snippet = result.find(\"div\", class_=\"gs_a\").text\n",
    "            \n",
    "            # Extract conference or journal name from snippet\n",
    "            conference_or_journal = None\n",
    "            publisher = None\n",
    "            year = None\n",
    "            \n",
    "            snippet_parts = snippet.split(\"-\")\n",
    "            if len(snippet_parts) > 1:\n",
    "                conference_or_journal = snippet_parts[1].strip()\n",
    "                publisher_info = snippet_parts[1].strip()\n",
    "                # Extract year from the publisher_info\n",
    "                year_part = snippet_parts[-1].strip()\n",
    "                year = ''.join(filter(str.isdigit, year_part)) if any(char.isdigit for char in year_part) else None\n",
    "            \n",
    "            # Extract citations count\n",
    "            citations = None\n",
    "            citation_info = result.find(\"div\", class_=\"gs_fl\").find_all(\"a\")\n",
    "            for a in citation_info:\n",
    "                if \"Cited by\" in a.text:\n",
    "                    citations = a.text.split(\"Cited by \")[-1]\n",
    "\n",
    "            keywords = [] \n",
    "            abstract = result.find(\"div\", class_=\"gs_rs\")\n",
    "            if abstract:\n",
    "                abstract_text = abstract.text  # Keep original case for replacements\n",
    "                \n",
    "                # Perform replacements first\n",
    "                replacements = {\n",
    "                    \"DL\": \"deep learning\",\n",
    "                    \"NLP\": \"natural language processing\",\n",
    "                    \"CV\": \"computer vision\",\n",
    "                    \"CNN\": \"convolutional neural networks\",\n",
    "                    \"RNN\": \"recurrent neural networks\",\n",
    "                    \"Gen AI\": \"generative adversarial networks\",\n",
    "                    \"IOT\": \"internet of things\",\n",
    "                    \" AR \": \"augmented reality\",\n",
    "                    \" R \": \"Programming Concepts\",\n",
    "                    \" C++ \": \"Programming Concepts\",\n",
    "                    \" C \": \"Programming Concepts\",\n",
    "                    \" Java \": \"Programming Concepts\",\n",
    "                    \" Python \": \"Programming Concepts\",\n",
    "                    \" SQL \": \"Database\",\n",
    "                    \" MongoDB \": \"Database\",\n",
    "                }\n",
    "                for short_form, full_form in replacements.items():\n",
    "                    abstract_text = abstract_text.replace(short_form, full_form)\n",
    "                \n",
    "                # Convert the text to lowercase after replacements\n",
    "                abstract_text = abstract_text.lower()\n",
    "                \n",
    "                # Define possible keywords\n",
    "                possible_keywords = [\n",
    "                    \"machine learning\", \n",
    "                    \"deep learning\",  # Includes \"DL\"\n",
    "                    \"big data\", \n",
    "                    \"artificial intelligence\", \n",
    "                    \"natural language processing\",  # Includes \"nlp\"\n",
    "                    \"computer vision\",  # Includes \"cv\"\n",
    "                    \"reinforcement learning\", \n",
    "                    \"data mining\", \n",
    "                    \"predictive analytics\", \n",
    "                    \"supervised learning\", \n",
    "                    \"unsupervised learning\", \n",
    "                    \"convolutional neural networks\",  # Includes \"cnn\"\n",
    "                    \"recurrent neural networks\",  # Includes \"rnn\"\n",
    "                    \"generative adversarial networks\",  # Includes \"gen ai\"\n",
    "                    \"transfer learning\", \n",
    "                    \"cloud computing\",\n",
    "                    \"internet of things\",  # Includes \"iot\"\n",
    "                    \"robotics\", \n",
    "                    \"cybersecurity\", \n",
    "                    \"algorithm\", \n",
    "                    \"quantum computing\", \n",
    "                    \"programming concpts\",\n",
    "                    \"database\",\n",
    "                    \"augmented reality\"  # Includes \"ar\"\n",
    "                ]\n",
    "            \n",
    "                for keyword in possible_keywords:\n",
    "                    if keyword in abstract_text:\n",
    "                        keywords.append(keyword)\n",
    "            if title:\n",
    "                title_text = title  # Keep original case for replacements\n",
    "                \n",
    "                # Perform replacements first\n",
    "                replacements = {\n",
    "                    \"DL\": \"deep learning\",\n",
    "                    \"NLP\": \"natural language processing\",\n",
    "                    \"CV\": \"computer vision\",\n",
    "                    \"CNN\": \"convolutional neural networks\",\n",
    "                    \"RNN\": \"recurrent neural networks\",\n",
    "                    \"Gen AI\": \"generative adversarial networks\",\n",
    "                    \"IOT\": \"internet of things\",\n",
    "                    \" AR \": \"augmented reality\",\n",
    "                    \" R \": \"Programming Concepts\",\n",
    "                    \" C++ \": \"Programming Concepts\",\n",
    "                    \" C \": \"Programming Concepts\",\n",
    "                    \" Java \": \"Programming Concepts\",\n",
    "                    \" Python \": \"Programming Concepts\",\n",
    "                    \" SQL \": \"Database\",\n",
    "                    \" MongoDB \": \"Database\",\n",
    "                }\n",
    "                for short_form, full_form in replacements.items():\n",
    "                    title_text = title_text.replace(short_form, full_form)\n",
    "                \n",
    "                # Convert the text to lowercase after replacements\n",
    "                title_text = title_text.lower()\n",
    "                \n",
    "                # Define possible keywords\n",
    "                possible_keywords = [\n",
    "                    \"machine learning\", \n",
    "                    \"deep learning\",  # Includes \"DL\"\n",
    " \n",
    "                    \"big data\", \n",
    "                    \"artificial intelligence\", \n",
    "                    \"natural language processing\",  # Includes \"nlp\"\n",
    "                    \"computer vision\",  # Includes \"cv\"\n",
    "                    \"reinforcement learning\", \n",
    "                    \"data mining\", \n",
    "                    \"predictive analytics\", \n",
    "                    \"convolutional neural networks\",  # Includes \"cnn\"\n",
    "                    \"recurrent neural networks\",  # Includes \"rnn\"\n",
    "                    \"generative adversarial networks\",  # Includes \"gen ai\"\n",
    "                    \"transfer learning\", \n",
    "                    \"internet of things\",  # Includes \"iot\"\n",
    "                    \"robotics\", \n",
    "                    \"cybersecurity\", \n",
    "                    \"algorithm\", \n",
    "                    \"quantum computing\", \n",
    "                    \"programming concpts\",\n",
    "                    \"database\",\n",
    "                    \"augmented reality\"  # Includes \"ar\"\n",
    "                ]\n",
    "            \n",
    "                for keyword in possible_keywords:\n",
    "                    if keyword in title_text:\n",
    "                        keywords.append(keyword)\n",
    "\n",
    "            key = set(keywords)\n",
    "            # Append extracted information to the articles list\n",
    "            articles.append({\n",
    "                \"Title\": title,\n",
    "                \"Abstract\": abstract.text,\n",
    "                \"Publisher\": publisher,\n",
    "                \"Year\": year,\n",
    "                \"Conference/Journal\": conference_or_journal,\n",
    "                \"Keywords\": key,\n",
    "                \"Citations Count\": citations\n",
    "            })\n",
    "\n",
    "        page += 1\n",
    "        \n",
    "        # Add a delay between requests to avoid getting blocked\n",
    "        time.sleep(random.uniform(1, 5))  # Random delay between 1 to 5 seconds\n",
    "\n",
    "    return articles\n",
    "\n",
    "def save_to_excel(articles, filename):\n",
    "    df = pd.DataFrame(articles)\n",
    "    df.to_excel(filename, index=False)\n",
    "\n",
    "def browse_folder():\n",
    "    folder_path = filedialog.askdirectory()\n",
    "    entry_folder.delete(0, tk.END)\n",
    "    entry_folder.insert(tk.END, folder_path)\n",
    "\n",
    "def scrape_articles():\n",
    "    query = entry_query.get()\n",
    "    num_pages = int(entry_pages.get())\n",
    "\n",
    "    articles = scrape_scholar_articles(query, num_pages)\n",
    "\n",
    "    folder_path = entry_folder.get()\n",
    "    if folder_path:\n",
    "        filename = f\"{folder_path}/G_phs.xlsx\"\n",
    "    else:\n",
    "        filename = \"scholar_articles.xlsx\"\n",
    "\n",
    "    save_to_excel(articles, filename)\n",
    "    label_status.config(text=\"Extraction complete. Data saved to scholar_articles.xlsx.\")\n",
    "\n",
    "# Create the main window\n",
    "window = tk.Tk()\n",
    "window.title(\"Google Scholar Scraper\")\n",
    "window.geometry(\"400x250\")\n",
    "\n",
    "# Create input fields and labels\n",
    "label_query = tk.Label(window, text=\"Article Title or Keyword:\")\n",
    "label_query.pack()\n",
    "entry_query = tk.Entry(window, width=40)\n",
    "entry_query.pack()\n",
    "\n",
    "label_pages = tk.Label(window, text=\"Number of Pages:\")\n",
    "label_pages.pack()\n",
    "entry_pages = tk.Entry(window, width=40)\n",
    "entry_pages.pack()\n",
    "\n",
    "label_folder = tk.Label(window, text=\"Output Folder (optional):\")\n",
    "label_folder.pack()\n",
    "entry_folder = tk.Entry(window, width=40)\n",
    "entry_folder.pack()\n",
    "\n",
    "# Create browse button\n",
    "button_browse = tk.Button(window, text=\"Browse\", command=browse_folder)\n",
    "button_browse.pack()\n",
    "\n",
    "# Create extract button\n",
    "button_extract = tk.Button(window, text=\"Extract Data\", command=scrape_articles)\n",
    "button_extract.pack()\n",
    "\n",
    "# Create status label\n",
    "label_status = tk.Label(window, text=\"\")\n",
    "label_status.pack()\n",
    "\n",
    "# Run the main window loop\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba23914c-3c45-453e-941d-516def8216a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
